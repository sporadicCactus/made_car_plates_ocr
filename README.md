Мой пайплайн состоял из двух сетей --- детектора и распознавателя. Детектор находит номера (уголки номерной пластины), при помощи перспективного преобразования номер приводится к форме 97\*65 пикселей и проходит через распознаватель. Распознаватель ---  resnet34 с макспулингом и полносвязным слоем, выход которого имеет форму 9*(число символов + 1). Распознавалка показывала рекультат в 0.28 ошибки (в смысле редакционного расстояния) на номер на валидации. Экспериментам с распознавалкой я почти не успел уделить времени, так как хотелось завести детектор на основе идей из

1. [Zhu el al., Feature Selective Anchor-Free Module for Single-Shot Object Detection](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Feature_Selective_Anchor-Free_Module_for_Single-Shot_Object_Detection_CVPR_2019_paper.pdf)

2. [Tian et al., Fcos: Fully convolutional one-stage object detection](http://openaccess.thecvf.com/content_ICCV_2019/papers/Tian_FCOS_Fully_Convolutional_One-Stage_Object_Detection_ICCV_2019_paper.pdf)

Для детектора я брал преобученный faster_rcnn на resnet50 + fpn из torchvision'а, выдирал из него собственно resnet50 + fpn (там, кстати, засада --- batchnorm слои заморожены. Заменил на нормальные, но заметил далеко не сразу...), добавлял голову (две ветви --- классификация и регрессия --- четыре 3х3 свёрточный слоя). Помимо бокса и углов номера ветвь регрессии предсказывала "центровость", как описано во второй статье.

Фотографии предобрабатывались следующим образом: на фотографии случайным образом выбирается номер и вокруг него вырезается такая область, что линейные размеры номера лежат в диапазоне от 30 пикселей до ~ 180 пикселей (масштаб случаен, вся область приводится к размеру 224\*224). При этом применяется случайный набор аугументаций, в том числе случайные вращения. Если другие номера попадают в кропнутую область (и от них "отрезается" менее 50% их видимой площади), они также считаются положительными примерами. С некоторой вероятностью область кропалась не вокруг какого-то номера, а просто случайным образом.

Батчи обработанных изображений далее склеивались в одно изображение (т.е. батч из восьми 224\*224 изображений склеивается в одну 448\*896 картинку). Так как скорость предобработки изображений оказывалась бутылочным горлышком в пайплайне обучения, батчи один и тех же изображений переиспользовались: создавалась FIFO очередь из склеенных картинок(например, размера 448\*896, полученных из 8 обрезанных номеров), которые затем склеивались в единый батч (т.е. тензор размера [n, 3, 448, 896]) и подавались на вход сети. Таким образом один и тот же батч переиспользовался n раз за эпоху. Чтобы смягчить переобучение, градиент ошибки тек в изображения и суммировался с ними (при этом градиент в каждом пикселе обрезался по модулю). Таким образом получалось что-то вроде self-adversarial training'а.

Хорошо обучить сеть в итоге не очень получилось. При этом основная проблема была с регрессией уголков номеров. Замена smooth_l1 на wingloss несколько повысила точность, но не принципиально. В конце я успел заменить resnet50 на resnet18, и достиг не сильно худшей точности. Возможно, где-то был баг, или голова из четырёх 3x3 свёрток была бутылочным горлышком. Буду ещё эксперементировать с описанным подходом...

На инференсе при детекции фотография обрабатывалась в нескольких масштабах: оригинальном, ужатом в 2, 4, 8 раз (чтобы не потерять крупные номера и в целом повысить качество). Результаты объединялись при помощи soft-nms'а. При создании сабмита использовался ещё один небольшой хак: граничные значения soft-nms'а в детекторе занижались для увеличения recall'а, а средение значения скоров классификации распознавателя использовались для отбрасывания ложных детекций. Отсекающее значение выбиралось на основании распределения средних скоров при фиксированном числе ошибок на валидационном множестве.



P.S. Я ещё выкладывал бэйзлайн до того, как был выложен "официальный". За него, вроде, полагаются дополнительные баллы?..

P.P.S. Большое спасибо за классный курс и суперынтересные соревнования! 
